---
title: "ユーザーの全期間追跡を低コストで実現する dbt モデル設計"
emoji: "📊"
type: "tech"
topics: ["dbt", "BigQuery"]
published: false
publication_name: "pivotmedia"
---

## 1. はじめに

[ビジネス映像メディア「PIVOT」](https://pivotmedia.co.jp/app) データエンジニアの uma-chan です。

今回は dbt を軸にデータ分析を促進する一助となった事例を紹介します。

## 2. 初期実装時の課題

ユーザーの流入元分析を実施する中で、以下のようなモデルを新規作成してデータ分析に貢献しようとしました。

- 流入元別の継続率分析 (初回訪問から N 週間後に再訪問したかなど)
- ユーザーの初回訪問と最終訪問の追跡
- 長期的な視点でのユーザー獲得品質の評価

初期実装はあまり深く考えずに以下のように実装し、Out Of Memory (OOM) エラーとなりました。

- FIRST_VALUE/LAST_VALUE ウィンドウ関数で全期間データを走査
- 全ユーザーの全期間データをメモリに展開

## 3. 実施した改善策

### 3.1. incremental (差分更新) に向いているモデル設計への作り直し

データ量の増加に伴い集計コストが増大することを避けたいため、全期間を低コストで追跡する方法として「incremental に向いているモデル設計」という基本を押さえるべきですね。

#### 3.1.1. incremental (差分更新) 処理実行時のロジック設計

重要項目を先に決めます。

- ユニークキーは複数経路で付与されるユーザーIDを極力横断的に統一したもの
- 初回訪問の情報として全期間の初回訪問を記録し続ける (= 更新しない)
- 最終訪問の場合、常に最新に更新する

#### 3.1.2. 事前集約モデルの新規作成

モデル設計を修正した後、ウィンドウ関数を削除し、代わりに事前集約モデルを新規作成しました。

変更前は下流モデルでウィンドウ関数を使用していました。

変更後は上流モデルで事前集約 (incremental) し、下流モデルは事前集約を LEFT JOIN するだけになりました。

なぜこれで解決するかを説明します。

- ウィンドウ関数は全期間データをメモリに展開する必要がある
- 事前集約モデルは 1ユーザー1レコードなので、JOIN が高速
- 事前集約モデルが incremental にしやすい設計になっているため、データ量が増えても問題ない

#### 3.1.3. incremental で追跡可能な指標の追加

基本的な first_touch / last_touch に加えて、incremental でも正確に追跡できる指標を追加しました。

プラットフォーム遷移追跡

- app_first_activation_date (アプリ初回起動日 - MIN で保持)
- app_first_platform (アプリ初回起動プラットフォーム - 初回のみ設定)
- last_web_touch_date (Web最終訪問日 - MAX で更新)
- last_app_touch_date (アプリ最終訪問日 - MAX で更新)
- platform_transition_pattern (Web→App 転換パターン - ルールベース判定)

流入経路分類

- first_touch_channel (初回流入チャネル - 初回のみ設定)
- is_paid_acquisition (有料広告経由フラグ - 初回のみ設定)

時系列情報

- days_to_app_activation (Web初回訪問からアプリ起動までの日数 - 計算)
- days_since_last_touch (最終訪問からの経過日数 - 毎回更新)
- user_lifetime_days (初回訪問からの経過日数 - 毎回更新)

これらの指標がなぜ incremental で追跡できるかを説明します。

- MIN/MAX 系の指標は既存データと新規データを比較するだけで正しい結果が得られる
- 初回のみ設定する指標は既存データがあれば上書きしない
- 計算系の指標は MIN/MAX から導出できる
- 累積合計 (SUM) や平均 (AVG) と異なり、元データが不要

#### 3.1.4. パラメータ最適化

incremental 実行時のルックバック期間をデフォルト 14日 から 3日 に変更しました。

定期実行が 6時間ごとのため、3日分で十分です。初回訪問情報は既存データと比較して古い方を保持するため、3日分のデータを見るだけで全期間の初回訪問情報を正しく保持できます。

パラメータ最適化も「incremental 実行を前提とした設計」の一部です。ルックバック期間を短くできるのは、incremental ロジックが正しく設計されているからです。

### 3.2. モデルがもたらす価値

このモデル設計により、以下の価値を生み出すことができました。

長期的な視点での分析が可能に (最大の価値)

変更前の場合、全期間の初回訪問情報を得るには、全ユーザーの全期間データを走査する必要がありました (重い、OOMになる)

変更後の場合、incremental で直近3日分だけ処理すれば、全期間の初回訪問情報が正確に得られます (軽い、速い)

なぜ可能かを以下に示します。

- 既存データと新規データを比較して古い方を保持する設計
- incremental でも全期間の情報を正しく維持できる
- 処理データ量は約 303 MiB (全期間処理の 1/90 以下)

これが意味することを以下に示します (ただし MIN/MAX 系の指標に限る)

- 初回訪問や最終訪問のような指標で長期的な視点を持って分析できる
- 本来は膨大なデータを集計しないと得られない MIN/MAX 系の結果が、低コストで得られる
- 更新コストが低い (6時間ごとの incremental 実行でも問題ない)
- データ量が増えても、処理時間とコストが増えない
- サービス開始からの全ユーザーの初回訪問・最終訪問情報を、常に最新状態で保持できる

再利用可能な基礎データとして機能

- 他の分析モデルからも参照できる
- ユーザーの訪問情報が一元化される
- 下流モデルは JOIN するだけで全期間の情報が得られる

### 3.3. データ品質改善

モデル作成時に、以下のデータ品質改善も実施しました。

- 異常なユーザーIDを除外
- データソースの初期値や異常データを除去

## 4. 効果と検証

### 4.1. パフォーマンス改善

事前集約モデル (全期間処理、400日分) の結果です。

- 行数は約190万行
- 処理データ量は 24.6 GiB
- 実行時間は約6分47秒
- 1ユーザー1レコードを保証

下流モデル (全期間処理、180日分) の結果です。

- 行数は約98万行
- 処理データ量は 27.7 GiB
- 実行時間は約1分20秒
- OOM 発生なし

### 4.2. incremental 実行時

incremental 実行時の結果です。

- 処理データ量は約 303 MiB (全期間処理の 1/90 以下)
- 初回訪問情報が正しく保持されることを確認
- レコードの重複なし

## 5. おわりに

first_touch / last_touch という特定の指標の全期間追跡を実現するために、「incremental に向いているモデル設計」という基本を押さえることにしました。結果的に、OOM は解消でき、さらに予想以上の価値を生み出すことができました。

得られた成果を以下に示します。

- OOM 解消 (当初のきっかけ)
- 低コストでの運用 (副次的効果)
- MIN/MAX 系の指標で長期的な視点での分析が可能に (最大の価値)

ただし、このアプローチは SUM (全期間の合計) などの累積的な指標には適用できません。あくまで既存データと新規データを比較するだけで正しい結果が得られる指標 (MIN/MAX 系) に限定されます。

基本を押さえることで、一つの課題を解決するだけでなく、複数の価値を同時に生み出すことができました。

学んだことを以下に示します。

- unique_key に「incremental 実行のたびに変わる値」を含めてはいけない
- incremental 実行時のロジックを明確に設計する
- パラメータ最適化も設計の一部

どんな指標なら incremental で追えるかについて説明します。

この経験から、incremental で効率的に追跡できる指標のパターンが見えてきました。

incremental で追える指標を以下に示します。

- first_touch (初回訪問) では既存データと比較して古い方を保持
- last_touch (最終訪問) では常に最新に更新
- MIN/MAX 系の指標では既存と新規を比較して適切な方を選択

incremental では難しい指標を以下に示します。

- 全期間の合計 (SUM) では毎回全期間を走査する必要がある
- 複雑な集計 (平均、中央値など) では元データが必要
- UNBOUNDED なウィンドウ関数では全期間データをメモリ展開

判断基準を説明します。

「既存データと新規データを比較するだけで、正しい結果が得られるか」

この基準で考えると、どの指標を事前集約モデルに入れるべきか判断できます。

重要な注意点として、このアプローチは MIN/MAX のような比較可能な指標に限定されます。SUM (累積合計) や AVG (平均) のように元データが必要な指標には使えません。このモデルは初回訪問・最終訪問という特定の用途に特化したモデルであり、あらゆる分析に対応できるわけではありません。

基本的なことですが、見落としがちです。

dbt のドキュメントには incremental_strategy や unique_key について書かれていますが、「incremental 実行のたびに変わる値を unique_key に含めてはいけない」という注意点や「どんな指標なら incremental で追えるか」という判断基準は見落としがちでした。

この経験から、incremental モデルを設計する際は「incremental 実行時に何が起こるか」「この指標は incremental で追えるか」を常に意識するようになりました。

BigQuery の挙動と dbt の incremental モデルへの習熟度がまだまだなので引き続き学びを深めたいです。
